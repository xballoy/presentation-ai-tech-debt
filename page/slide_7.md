---
layout: two-cols-header
---

# Comment fonctionne un LLM ?

Les deux Ã©tapes clÃ©s pour crÃ©er un LLM :

::left::

<v-clicks>
<div>

**Pre-training** : les modÃ¨les analysent des milliards d'exemples de texte, apprenant Ã  prÃ©dire ce qui vient ensuite

<div class="text-sm mt-4 text-gray-600">

ğŸ’° Millions de $ / â±ï¸ Semaines/mois / ğŸ–¥ï¸ Milliers de GPU

</div>
</div>

</v-clicks>

::right::

<v-clicks>

<div>

**Fine-tuning** : les modÃ¨les sont affinÃ©s pour suivre des instructions, Ãªtre utiles et Ã©viter le contenu nuisible

<div class="text-sm mt-4 text-gray-600">

ğŸ“Š Moins de donnÃ©es / ğŸ‘¤ Feedback humain / âœ… Comportement souhaitÃ©

</div>
</div>

</v-clicks>

<style>
.two-cols-header {
  column-gap: 16px;
}
</style>

<!--
**Timing**: 2 minutes

**Objectif**: DÃ©mystifier les LLMs - ce ne sont pas des oracles magiques.

**Talking points**:
- "Pour comprendre comment utiliser l'IA, il faut comprendre comment elle est crÃ©Ã©e"
- "Pre-training = apprentissage massif sur internet, livres, code"
- "CoÃ»te des millions de dollars - c'est pourquoi VOUS ne pouvez pas en crÃ©er un"
- "Fine-tuning = on apprend au modÃ¨le Ã  suivre des instructions, Ãªtre utile"
- "Moins cher, utilise le feedback humain"
- "Pre-training utilise Next Token Prediction sur des corpus massifs"
- "Fine-tuning inclut instruction-tuning et RLHF (Reinforcement Learning from Human Feedback)"
- "C'est pourquoi certains modÃ¨les sont meilleurs pour le code (fine-tuned sur GitHub)"

**Pourquoi c'est important pour la dette technique**:
- "Pre-training = le modÃ¨le a VU beaucoup de code legacy et moderne"
- "Fine-tuning = il a appris Ã  AIDER les dÃ©veloppeurs"
- "Mais il ne connaÃ®t pas VOTRE contexte - c'est pourquoi la validation est critique"

**Transition vers slide 6**:
"Maintenant, que se passe-t-il quand vous lui envoyez un prompt?"

**Ã‰nergie**: PÃ©dagogique - enseigner les fondamentaux
-->
